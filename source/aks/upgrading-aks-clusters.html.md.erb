---
title: Upgrading AKS Clusters
weight: 30
last_reviewed_on: 2024-01-24
review_in: 6 months
---

# <%= current_page.data.title %>

This run book documents some tasks that we have to perform when upgrading any of the AKS Clusters.  If you need to rebuild a cluster, please refer to the [rebuild guide](rebuilding-aks-clusters.html)

## Cluster Order of Upgrading

This is the normal order we use when upgrading clusters, it does not have to exactly follow it:

- Sbox             - (cft-sbox-00-aks, cft-sbox-01-aks/ ss-sbox-00-aks, ss-sbox-01-aks)
- Ptlsbox          - (cft-ptlsbox-00-aks/ ss-ptlsbox-00-aks)
- ITHC             - (cft-ithc-00-aks, cft-ithc-01-aks/ ss-ithc-00-aks, ss-ithc-01-aks)
- Preview          - (cft-preview-01-aks/ ss-dev-01-aks)
- Demo             - (cft-demo-00-aks, cft-demo-01-aks/ ss-demo-00-aks, ss-demo-01-aks)
- Perftest         - (cft-perftest-00-aks, cft-perftest-01-aks/ ss-test-00-aks, ss-test-01-aks)
- AAT              - (cft-aat-00-aks, cft-aat-01-aks/ ss-stg-00-aks, ss-stg-01-aks)
- Production       - (prod-00-aks, prod-01-aks/ ss-prod-00-aks, ss-prod-01-aks) 
- Ptl              - (cft-ptl-00-aks/ ss-ptl-00-aks) 

## Pods and HRs Health Checks

Please post a notification in the #cloud-native-announce channel to notify people which clusters will be upgraded (Please refrain from using @here, as this is intended for notifications rather than announcements).
Utilize the #sds-cloud-native channel if you are involved in activities concerning SDS clusters. 
This will help inform others about the specific clusters undergoing upgrades.

Ensure your logged into the correct cluster.

```command
kubectl config current-context
```

Before upgrading any of the clusters run the following query on the cluster you are planning to upgrade to find out the statuses of the pods and hrs:

```command
kubectl get pods -A | wc -l > pods_total_count && kubectl get pods -A > pods_all_status && kubectl get pods -A | awk '!/(Running|Succeeded)/' > pods_not_running_or_succeeded && kubectl get hr -A > hr_all_status
```
Once completed compare the hrs and pods statuses with the ones you saved before the upgrade took place.

Three files will be saved in the directory from which you are running the above command and "ll" in the cli to display the files. 

- Check if pluto needs updating on the cluster

```command
pluto detect-helm -owide --target-versions k8s=v1.26 --only-show-removed
```

- Investigate failed helm releases and pods in CrashLoopBackOff or ImagePullBackOff Status. 

```command
kubectl get helm --all-namespaces / kubectl get pods --all-namespaces
```

- Check if these pods have pod disruption budgets 

```command
kubectl get pdb -A
```

- If there is a pod disruption budget associated with the application pod and the Allowed Disruptions is set to 0 do not proceed with the cluster upgrade until this application pod is back up and running or it will block the upgrade.

- For failed helm releases where pods are not deployed, test if rolling back to a previous successful release (which helps narrow down issue being specific to current release). 

- To list all failed helm releases

```command
kubectl get hr --all-namespaces | grep False
```
- To view helm chart history

```command
helm history <chart name> -n <namespace>
```
- To roll back helm chart to a prior version or specific version

```command
helm rollback <chart name> -n <namespace> / helm rollback <chart name> <version number> -n <namespace>
```

- For failed pods, investigate root cause and discuss with teams as required (e.g. pods not starting due to missing keyvault secrets)

```command
helm rollback <chart name> -n <namespace> / helm rollback <chart name>  <version number> -n <namespace>
```

- For pods where images beginning with pr- are not found this is often due to the image no longer existing in the ACR. In these, instances you will need to either reach out to the app teams to get it updated or find the latest prod image for that pod in the ACR and put in a PR to fix like this [one](https://github.com/hmcts/cnp-flux-config/pull/17115/files) done previously.

- To find by an app team, search this [file] (https://github.com/hmcts/cnp-jenkins-config/blob/master/team-config.yml) with the name of the namespace the pod is in. Under the "contact_channel", you will find the app teams slack channel for you to reach out on.

- For a non production environment (or a non live application in production) if the team cannot fix the issue quickly and it is not a common component then comment out the application in flux for the environment to unblock the upgrade, like the following [example](https://github.com/hmcts/cnp-flux-config/blob/8b049088445ee0ac282bb85eb3d28d94f202c252/clusters/ithc/base/kustomization.yaml#L14C2-L14C2).

## Common Upgrade Steps

The upgrade process begins by removing the cluster you are going to upgrade from the application gateway. This is step is not required for single clusters.

  - [PR example for SDS here](https://github.com/hmcts/sds-azure-platform/pull/473/files)
  - [PR example for CFT here](https://github.com/hmcts/azure-platform-terraform/pull/580/files)

Unsure which IP belongs to which cluster? Check the front end IP of the kubernetes-internal loadbalancer: 

[portal.azure.com](https://portal.azure.com) > Load Balancer > search for 'kubernetes-internal' > filter by the Resource Group > click on the load balancer returned by the search > click on Frontend IP Configuration > the IP Address is the one you need

##  Environment Specific Steps
Some environments do have some additional requirements / checks that need to be confirmed prior to upgrading any of its clusters.
We upgrade PTL/PTLSbox and Preview/Dev in-place, meaning we aren't building another cluster or switching in the appgw unless necessary. If one of these environments must instead be rebuilt and swapped over, please refer to the Rebuilding AKS Clusters guide.

### Ptlsbox, Ptl
Make an announcement that Jenkins may be briefly unavailable in the #cloud-native-announce slack channel. It is recommended to issue this announcement early in the morning. 
Subsequently, please verify the status of [Jenkins instances](https://build.hmcts.net/) to ensure they are operational following the upgrades. 

## Upgrading the Cluster

Find the cluster you want to upgrade into the portal, which should have been removed from app gateway.

Cluster Configuration > Upgrade Version > in the Kubernetes version drop down menu choose the latest GA version > Click Save

This will trigger the upgrade of the cluster, which will take some time. Once this has finished you need to create a pull request to update the code to match.

- [SDS repo](https://github.com/hmcts/aks-sds-deploy/blob/master/environments/aks/ptlsbox.tfvars#L3)
- [CFT repo](https://github.com/hmcts/aks-cft-deploy/blob/main/environments/aks/demo.tfvars#L3)

We do this upgrade manually in the portal because it means we don't have terraform state issues when the upgrade times out if there was a failure due to failing pods or some other reason.

<%= warning_text('The <code>kubernetes_version</code> value only takes major version values, i.e 1.25, 1.26 and so on.') %>

Once the changes have been reviewed, approved and merged, run the pipeline for the environment you are upgrading to have terraform update the state:

- [SDS Pipeline](https://dev.azure.com/hmcts/PlatformOperations/_build?definitionId=482)
- [CFT Pipeline](https://dev.azure.com/hmcts/PlatformOperations/_build?definitionId=766)

Once completed compare the `hrs` and pods statuses with the ones you saved before the upgrade took place.

<%= warning_text('Issues during an AKS Upgrade')%>
[Troublehsooting upgrade failures](known-issues.html)

## After upgrading of a cluster
- Add the cluster back into the application gateway once you have confirmed the upgrade has been successful.
  - [SDS example](https://github.com/hmcts/sds-azure-platform/pull/474/files)
  - [CFT example](https://github.com/hmcts/azure-platform-terraform/pull/595/files)